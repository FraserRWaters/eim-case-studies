---

Title: Superintelligence

Template: ListSubPages

---


**Superintelligence: Paths, Dangers, Strategies** by Oxford philosopher Nick Bostrom : In his book, Bostrom talks about the "intelligence explosion" that will occur when machines which are more intelligent than humans begin to design machines of their own. The general point that the book is trying to push is summarised nicely by Tim Adams, who wrote an article for the Guardian following an interview with Bostrom,	"If we create a machine intelligence superior to our own, and then give it freedom to grow and learn through access to the internet, there is no reason to suggest that it will not evolve strategies to secure its dominance, just as in the biological world." Whilst 'Superintelligence' contains some important philosophical and ethical points about why we should be careful about AI and the creation of superintelligence, the book is purely speculative and not aimed at mathematicians - despite being endorsed by many technically minded people. In Chapter 4, there is some 'mathematics' which 'analyses the kinetics of the transition to superintelligence as a function of optimisation power and system recalitrance,' defining

	$$\text{rate of change of intelligence}=\frac{\text{optimisation power}}{\text{recalitrance}}$$.
